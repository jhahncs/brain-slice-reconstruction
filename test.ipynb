{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d84ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import test_pipeline\n",
    "import slice_util\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = '/home/jhahn/puzzlefusion-plusplus/config'\n",
    "files_root =  '/home/jhahn/puzzlefusion-plusplus/web/files'\n",
    "data_ids = ['sliced_on_0_0_1_0.001_10_100_700']#['0408']\n",
    "tickness = 0.001\n",
    "spacing = 0.007\n",
    "ckpt_path= '/home/jhahn/puzzlefusion-plusplus/brain_lightsheet/denoiser/everyday_2000epoch/training/last.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3ef656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiff_dir_root /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/tiff\n",
      "obj_dir_root /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/objs\n",
      "pc_dir_root /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/pc\n",
      "inference_dir_root /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/inference\n",
      "render_output_dir /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import puzzlefusion_plusplus.denoiser.dataset.dataset\n",
    "importlib.reload(puzzlefusion_plusplus.denoiser.dataset.dataset)\n",
    "from puzzlefusion_plusplus.denoiser.dataset.dataset import build_test_dataloader\n",
    "import test_pipeline\n",
    "importlib.reload(test_pipeline)\n",
    "\n",
    "cfg = test_pipeline.load_cfg(config_dir)\n",
    "tiff_dir_root, obj_dir_root, pc_dir_root, inference_dir_root, render_output_dir = test_pipeline.init_dir(files_root,data_ids)\n",
    "print('tiff_dir_root',tiff_dir_root)\n",
    "print('obj_dir_root',obj_dir_root)\n",
    "print('pc_dir_root',pc_dir_root)\n",
    "print('inference_dir_root',inference_dir_root)\n",
    "print('render_output_dir',render_output_dir)\n",
    "\n",
    "tiff_dir = '/data/jhahn/data/brain_lightsheet/slices/sliced_on_0_0_1'\n",
    "\n",
    "'''\n",
    "for f in os.listdir(tiff_dir):\n",
    "    _id = int(f.split(\".\")[-2])\n",
    "    if _id % 6 == 0:\n",
    "        #print(f, _id, tiff_dir_root,tiff_dir + \"/\" + f)\n",
    "        shutil.copyfile(tiff_dir + \"/\" + f, tiff_dir_root + \"/\"+ f )    \n",
    "'''\n",
    "\n",
    "glb_dir = '/data/jhahn/data/shape_dataset/data/brain_lightsheet/sliced_on_0_0_1_0.001_10_100_700/fractured_0'\n",
    "for f in os.listdir(glb_dir):\n",
    "    _id = int(f.split(\".\")[-2])\n",
    "\n",
    "    shutil.copyfile(f'{tiff_dir}/{_id}.tif', f'{tiff_dir_root}/{_id}.tif')    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#tiff_filename_list_\n",
    "#for f in os.listdir(tiff_dir):\n",
    "\n",
    "#shutil.copyfile(orginal_filename,target_filename )       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "284a9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_tiff_2_obj: the number of jobs:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tiff_2_pcd: 100%|██████████| 19/19 [00:00<00:00, 14873.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/objs/test.txt\n",
      "-------------------------------------\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/objs/0.001\n",
      "folder: 0.001/fractured_0  num_parts: 19\n",
      "save_path /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/pc/0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/objs/0.001/fractured_0 ['100.glb', '110.glb', '120.glb', '130.glb', '140.glb', '150.glb', '160.glb', '170.glb', '180.glb', '190.glb', '200.glb', '210.glb', '220.glb', '230.glb', '240.glb', '250.glb', '260.glb', '270.glb', '280.glb']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test data: 100%|██████████| 1/1 [00:38<00:00, 38.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001/fractured_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obj_dir_list_relative = test_pipeline.tiff_2_obj(cfg, tiff_dir_root, tickness,spacing, obj_dir_root, pc_dir_root)\n",
    "#obj_dir_list_relative = ['0.001_0.007']\n",
    "#obj_dir_list_relative\n",
    "#obj_files = []\n",
    "#for _o in os.listdir(obj_dir_root+\"/\"+obj_dir_list_relative[0]+\"/fractured_0\"):\n",
    "#    obj_files.append(obj_dir_root+\"/\"+obj_dir_list_relative[0]+\"/fractured_0/\"+_o)\n",
    "#slice_util.combine_obj_files(obj_files, obj_dir_root+\"/\"+obj_dir_list_relative[0]+\"/combined.obj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8a3e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hydra': {'output_subdir': None, 'run': {'dir': '.'}}, 'defaults': ['_self_', 'denoiser/data', 'denoiser/model', 'denoiser/encoder', 'verifier/model', 'ae/model', 'ae/vq_vae', {'override hydra/hydra_logging': 'disabled'}, {'override hydra/job_logging': 'disabled'}], 'denoiser': {'ckpt_path': '/home/jhahn/puzzlefusion-plusplus/brain_lightsheet/denoiser/everyday_2000epoch/training/last.ckpt', 'data': {'val_batch_size': 1, 'matching_data_path': './data/matching_data/', 'batch_size': 64, 'num_workers': 64, 'data_fn': 'brain_lightsheet.{}.txt', 'data_dir': '/data/jhahn/data/shape_dataset/pc_data/brain_lightsheet/train/', 'data_val_dir': '/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/pc/0.001', 'mesh_data_dir': '/data/jhahn/data/shape_dataset/data', 'rot_range': -1, 'overfit': -1, 'min_num_part': 2, 'max_num_part': 20}, 'ae': {'ae_name': {'_target_': 'puzzlefusion_plusplus.denoiser.model.modules.encoder.VQVAE'}, 'n_embeddings': 1024, 'embedding_dim': 16, 'num_point': 25, 'num_dim': 64, 'local_decode_pts': 40, 'beta': 0.25}, 'hydra': {'output_subdir': None, 'run': {'dir': '.'}}, 'defaults': ['_self_', 'encoder', 'data', 'model', {'override hydra/hydra_logging': 'disabled'}, {'override hydra/job_logging': 'disabled'}], 'project_root_path': '${hydra:runtime.cwd}', 'experiment_output_path': '${project_root_path}/brain_10_parts/denoiser/${experiment_name}', 'experiment_name': None, 'train_seed': 123, 'test_seed': 123, 'logger': {'_target_': 'pytorch_lightning.loggers.WandbLogger', 'project': 'puzzlefusion_plusplus', 'name': '${experiment_name}', 'save_dir': '${experiment_output_path}/training'}, 'trainer': {'accelerator': 'gpu', 'max_epochs': 1000, 'num_sanity_val_steps': 1, 'check_val_every_n_epoch': 10, 'profiler': 'simple', 'precision': 32}, 'checkpoint_monitor': {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'monitor': 'eval/part_acc', 'mode': 'max', 'save_last': True, 'save_top_k': 3, 'every_n_epochs': '${trainer.check_val_every_n_epoch}', 'filename': '{epoch}', 'dirpath': '${experiment_output_path}/training'}, 'model': {'model_name': {'_target_': 'puzzlefusion_plusplus.denoiser.model.denoiser.Denoiser'}, 'encoder_weights_path': None, 'multiple_ref_parts': True, 'num_dim': 64, 'num_point': 25, 'out_channels': 7, 'std': 1, 'multires': 10, 'embed_dim': 512, 'num_layers': 6, 'num_heads': 8, 'dropout_rate': 0.1, 'DDPM_TRAIN_STEPS': 1000, 'DDPM_BETA_SCHEDULE': 'linear', 'timestep_spacing': 'leading', 'PREDICT_TYPE': 'epsilon', 'BETA_START': 0.0001, 'BETA_END': 0.02, 'num_inference_steps': 20, 'lr_scheduler': {'_target_': 'torch.optim.lr_scheduler.MultiStepLR', 'milestones': [1200, 1700], 'gamma': 0.5}}}, 'verifier': {'ckpt_path': None, 'threshold': 0.9, 'max_iters': 1}, 'experiment_name': None, 'train_seed': 123, 'test_seed': 123, 'accelerator': 'gpu', 'project_root_path': '${hydra:runtime.cwd}', 'experiment_output_path': '/data/jhahn/data/shape_dataset/inference_results/', 'inference_dir': '/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/inference', 'renderer': {'output_path': '/data/jhahn/data/shape_dataset/inference_results/', 'mesh_path': '/data/jhahn/data/shape_dataset/', 'num_samples': 300, 'duration': 6, 'extend_endframes': 20, 'min_parts': 2, 'max_parts': 20, 'category': 'all', 'ply_exists': True, 'material': 'plastic', 'save_gt': False, 'random_sample': True, 'blender': {'imgRes_x': 2048, 'imgRes_y': 2048, 'use_GPU': True, 'exposure': 1.5, 'numSamples': 200}, 'camera_kwargs': {'camera_type': 'orthographic', 'fit_camera': False, 'camPos': [3, 0, 2], 'camLookat': [0, 0, 0.5], 'camUp': [0, 1, 0], 'camHeight': 2.2, 'resolution': [256, 256], 'samples': 32, 'focalLength': 50}, 'light': {'lightAngle': [6, -30, -155], 'strength': 2, 'shadowSoftness': 0.3}, 'render_kwargs': {'preview': True, 'shadow_catcher': False}, 'colors': [[84, 107, 45], [178, 0, 0], [135, 206, 234], [239, 196, 15], [216, 112, 214], [255, 127, 79], [0, 127, 127], [237, 58, 130], [196, 237, 0], [0, 0, 127], [137, 53, 15], [112, 127, 142], [178, 127, 209], [255, 216, 178], [127, 127, 0], [53, 68, 79], [183, 75, 107], [70, 72, 107], [180, 123, 95], [137, 66, 70]]}, 'ae': {'ae': {'ae_name': {'_target_': 'puzzlefusion_plusplus.vqvae.model.modules.vq_vae.VQVAE'}, 'n_embeddings': 1024, 'embedding_dim': 16, 'num_point': 25, 'num_dim': 64, 'local_decode_pts': 40, 'beta': 0.25}, 'hydra': {'output_subdir': None, 'run': {'dir': '.'}}, 'defaults': ['_self_', 'vq_vae', 'data', 'model', {'override hydra/hydra_logging': 'disabled'}, {'override hydra/job_logging': 'disabled'}], 'project_root_path': '${hydra:runtime.cwd}', 'experiment_output_path': '${project_root_path}/brain_10_parts/autoencoder/${experiment_name}', 'ckpt_path': None, 'experiment_name': None, 'train_seed': 123, 'test_seed': 123, 'device': None, 'logger': {'_target_': 'pytorch_lightning.loggers.WandbLogger', 'project': 'puzzlefusion_plusplus', 'name': '${experiment_name}', 'save_dir': '${experiment_output_path}/training'}, 'trainer': {'accelerator': 'gpu', 'max_epochs': 1000, 'num_sanity_val_steps': 1, 'check_val_every_n_epoch': 10, 'profiler': 'simple', 'precision': 32}, 'checkpoint_monitor': {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'monitor': 'val_loss/cd_loss', 'mode': 'min', 'save_last': True, 'save_top_k': 3, 'every_n_epochs': '${trainer.check_val_every_n_epoch}', 'filename': '{epoch}', 'dirpath': '${experiment_output_path}/training'}, 'model': {'model_name': {'_target_': 'puzzlefusion_plusplus.vqvae.model.fracture_ae.FractureAE'}, 'lr_scheduler': {'_target_': 'torch.optim.lr_scheduler.MultiStepLR', 'milestones': [800, 1400], 'gamma': 0.5}}}, 'data': {'batch_size': 1, 'val_batch_size': 1, 'num_workers': 64, 'data_fn': 'brain_lightsheet.{}.txt', 'data_dir': '/data/jhahn/data/shape_dataset/pc_data/brain_lightsheet/train/', 'data_val_dir': '/data/jhahn/data/shape_dataset/pc_data/brain_lightsheet/val/', 'mesh_data_dir': '/data/jhahn/data/shape_dataset/data', 'rot_range': -1, 'overfit': -1, 'data_keys': ['part_ids'], 'num_pc_points': 1000, 'min_num_part': 2, 'max_num_part': 20, 'shuffle_parts': False, 'category': 'all', 'save_pc_data_path': '/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/pc/0.001'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 398.40it/s]\n",
      "/home/jhahn/puzzlefusion-plusplus/test_pipeline.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  denoiser_weights = torch.load(cfg.denoiser.ckpt_path)['state_dict']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe MIG 4g.40gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-e5a11831-23aa-537c-9ebe-5e6cce8a2bce,MIG-6b03ab11-3f04-52a2-952d-e8d9df38ee72]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3b212dce3c4107bddc2c184db5d673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_save_inference_data /home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/inference/0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval/part_acc                 0.0\n",
      "       eval/rmse_r          16.203292846679688\n",
      "       eval/rmse_t          0.04814939573407173\n",
      "      eval/shape_cd        0.014547410421073437\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 275.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import test_pipeline\n",
    "importlib.reload(test_pipeline)\n",
    "test_pipeline.inference(cfg, pc_dir_root, obj_dir_list_relative, ckpt_path, inference_dir_root)\n",
    "import importlib\n",
    "import render_inference_result\n",
    "importlib.reload(slice_util)\n",
    "importlib.reload(render_inference_result)\n",
    "import puzzlefusion_plusplus.denoiser.dataset.dataset\n",
    "importlib.reload(puzzlefusion_plusplus.denoiser.dataset.dataset)\n",
    "from puzzlefusion_plusplus.denoiser.dataset.dataset import build_test_dataloader\n",
    "\n",
    "\n",
    "vertices_gt = render_inference_result.get_vertices(inference_dir_root, obj_dir_root, device=test_pipeline.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15c8cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]/home/jhahn/puzzlefusion-plusplus/2d_2_pcd/render_inference_result.py:159: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  tr = Translate(torch.FloatTensor([init_trans]), dtype=torch.float32, device=device)\n",
      "100%|██████████| 19/19 [00:01<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/0.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/1.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/2.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/3.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/4.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/5.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/6.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/7.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/8.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/9.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/10.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/11.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/12.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/13.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/14.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/15.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/16.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/17.obj\n",
      "/home/jhahn/puzzlefusion-plusplus/web/files/sliced_on_0_0_1_0.001_10_100_700/render/0/trans/18.obj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 35.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0313, 0.0190, 0.0187, 0.0236, 0.0201, 0.0150, 0.0122, 0.0118, 0.0060,\n",
       "        0.0079, 0.0070, 0.0059, 0.0050, 0.0024, 0.0041, 0.0027, 0.0040, 0.0050,\n",
       "        0.0058], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_pipeline.inference(cfg, pc_dir_root, obj_dir_list_relative, ckpt_path, inference_dir_root)\n",
    "import importlib\n",
    "import render_inference_result\n",
    "importlib.reload(slice_util)\n",
    "importlib.reload(render_inference_result)\n",
    "import puzzlefusion_plusplus.denoiser.dataset.dataset\n",
    "importlib.reload(puzzlefusion_plusplus.denoiser.dataset.dataset)\n",
    "from puzzlefusion_plusplus.denoiser.dataset.dataset import build_test_dataloader\n",
    "import test_pipeline\n",
    "importlib.reload(test_pipeline)\n",
    "\n",
    "test_pipeline.render(inference_dir_root, vertices_gt, render_output_dir)\n",
    "shape_cd = test_pipeline.eval( vertices_gt,inference_dir_root,render_output_dir)\n",
    "shape_cd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
