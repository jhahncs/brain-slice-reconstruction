{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb03f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "inference_dir = '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100'\n",
    "data_dir = '/data/jhahn/data/shape_dataset/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b528e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb32c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/1', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/0', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/13', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/10', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/2', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/16', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/6', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/14', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/12', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/3', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/7', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/8', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/17', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/9', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/11', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/4', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/5', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/15']\n",
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 20.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.11152762174606323, 0.9047377109527588) (-1.5, 1) (0.05692139267921448, 0.7175641059875488)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 2/18 [00:00<00:01, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.0890, device='cuda:0') tensor(0.0900, device='cuda:0')\n",
      "1 tensor(0.0960, device='cuda:0') tensor(0.0970, device='cuda:0')\n",
      "2 tensor(0.1030, device='cuda:0') tensor(0.1040, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4/18 [00:00<00:01, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tensor(0.1100, device='cuda:0') tensor(0.1110, device='cuda:0')\n",
      "4 tensor(0.1170, device='cuda:0') tensor(0.1180, device='cuda:0')\n",
      "5 tensor(0.1240, device='cuda:0') tensor(0.1250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [00:00<00:00, 12.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 tensor(0.1310, device='cuda:0') tensor(0.1320, device='cuda:0')\n",
      "7 tensor(0.1380, device='cuda:0') tensor(0.1390, device='cuda:0')\n",
      "8 tensor(0.1450, device='cuda:0') tensor(0.1460, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 10/18 [00:00<00:00, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 tensor(0.1520, device='cuda:0') tensor(0.1530, device='cuda:0')\n",
      "10 tensor(0.1590, device='cuda:0') tensor(0.1600, device='cuda:0')\n",
      "11 tensor(0.1660, device='cuda:0') tensor(0.1670, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 14/18 [00:01<00:00, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 tensor(0.1730, device='cuda:0') tensor(0.1740, device='cuda:0')\n",
      "13 tensor(0.1800, device='cuda:0') tensor(0.1810, device='cuda:0')\n",
      "14 tensor(0.1870, device='cuda:0') tensor(0.1880, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [00:01<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 tensor(0.1940, device='cuda:0') tensor(0.1950, device='cuda:0')\n",
      "16 tensor(0.2010, device='cuda:0') tensor(0.2020, device='cuda:0')\n",
      "17 tensor(0.2080, device='cuda:0') tensor(0.2090, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 12.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import render_inference_result\n",
    "import obj_2_pcd\n",
    "import slice_util\n",
    "importlib.reload(slice_util)\n",
    "importlib.reload(obj_2_pcd)\n",
    "importlib.reload(render_inference_result)\n",
    "\n",
    "result_dir_list = []\n",
    "for f in os.listdir(inference_dir):\n",
    "    if os.path.isdir(inference_dir+\"/\"+f):\n",
    "        result_dir_list.append(inference_dir+\"/\"+f)\n",
    "print(result_dir_list)\n",
    "\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for _result_dir in result_dir_list[:1]:\n",
    "    #result_dir = f'{inference_dir}/1'\n",
    "    data_id = _result_dir.split(\"/\")[-1]\n",
    "\n",
    "    render_inference_result.gt_img(device,_result_dir, data_dir, output_dir)\n",
    "\n",
    "    render_inference_result.make_video(device,data_dir,_result_dir,output_dir )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f56a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/1', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/0', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/13', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/10', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/2', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/16', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/6', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/14', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/12', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/3', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/7', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/8', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/17', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/9', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/11', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/4', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/5', '/data/jhahn/data/shape_dataset/inference_results/inference/brain_lightsheet_from_100/15']\n",
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3/18 [00:00<00:00, 21.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0/0089.obj 0.08900000154972076 0.09000000357627869\n",
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0/0096.obj 0.09600000083446503 0.09700000286102295\n",
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0/0103.obj 0.10300000011920929 0.10400000214576721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0/0201.obj 0.20100000500679016 0.20200000703334808\n",
      "/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0.001_0089_215_rotate_test/fractured_0/0208.obj 0.20800000429153442 0.20900000631809235\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ef66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    \n",
    "\n",
    "gt = np.load(f'{result_dir}/gt.npy')\n",
    "print(gt.shape)\n",
    "\n",
    "init_pose = np.load(f'{result_dir}/init_pose.npy')\n",
    "print(init_pose.shape)\n",
    "\n",
    "predict_file_name = glob.glob(f'{result_dir}/predict*')[0]\n",
    "predict_0 = np.load(predict_file_name)\n",
    "#predict_0[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affbc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tiff_img_dir = '/data/jhahn/data/brain_lightsheet/0408'\n",
    "tiff_filename_list = []\n",
    "\n",
    "for tiff_filename in os.listdir(tiff_img_dir):\n",
    "    tiff_filename_full = f'{tiff_img_dir}/{tiff_filename}'\n",
    "    tiff_filename_list.append(tiff_filename_full)\n",
    "tiff_filename_list.sort(key = lambda x: int(x.split(\"/\")[-1].split(\".\")[-2]))\n",
    "\n",
    "#obj_dir = '/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408_0089_215_random_rotation/fractured_99'\n",
    "tickness = 0.001\n",
    "obj_dir = '0408'\n",
    "\n",
    "os.makedirs(obj_dir, exist_ok=True)\n",
    "\n",
    "offset_y_list = []\n",
    "tickness_list = []\n",
    "tiff_filename_full_list = []\n",
    "obj_dir_list = []\n",
    "obj_filename_list = []\n",
    "for _i, tiff_filename_full in enumerate(tiff_filename_list):\n",
    "    if _i >= 90 and _i <= 214:\n",
    "        if (_i - 90) % 6 == 0:\n",
    "            offset_y_list.append(tickness*_i)\n",
    "            tiff_filename_full_list.append(tiff_filename_full)\n",
    "            obj_dir_list.append(obj_dir)\n",
    "            tickness_list.append(tickness)\n",
    "    #obj_filename = obj_2_pcd.tiff_2_pcd(tickness*_i, tiff_filename_full, obj_dir, tickness)\n",
    "    #obj_filename_list.append(obj_filename)\n",
    "\n",
    "\n",
    "with multiprocessing.Pool() as pool: # Use a pool of 4 processes\n",
    "    obj_filename_list = pool.starmap(obj_2_pcd.tiff_2_pcd, zip(offset_y_list,tiff_filename_full_list,obj_dir_list, tickness_list))\n",
    "\n",
    "print(obj_filename_list)\n",
    "obj_dir = '0408_r'\n",
    "\n",
    "os.makedirs(obj_dir, exist_ok=True)\n",
    "\n",
    "angle = random.random()\n",
    "for obj_filename in obj_filename_list:\n",
    "    vertices = obj_2_pcd.load_obj(obj_filename)\n",
    "    vertices, _ = slice_util.random_rotation(vertices, angle)\n",
    "    with open(obj_dir+\"/\"+obj_filename.split(\"/\")[-1],'w') as f:\n",
    "        for xyz in vertices:\n",
    "            f.write(f'v {xyz[0]} {xyz[1]} {xyz[2]}\\n')\n",
    "\n",
    "\n",
    "import slice_util\n",
    "\n",
    "slice_util.combine_obj_files(['0408'],'output')\n",
    "slice_util.combine_obj_files(['0408_r'],'output')\n",
    "\n",
    "import render_inference_result\n",
    "import obj_2_pcd\n",
    "importlib.reload(obj_2_pcd)\n",
    "importlib.reload(render_inference_result)\n",
    "img_filename = 'output/0.png'\n",
    "render_inference_result.pcd_list_2_img(device, obj_filename_list, img_filename,xlim=(0,1),ylim=(0,2),zlim=(-2,2))\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=img_filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e3dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9516078 ,  0.88325334, -0.9407958 ,  0.53014946,  1.        ,\n",
       "        0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d9e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/1/gt.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(gt)\n\u001b[1;32m      4\u001b[0m init_pose \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/1/init_pose.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221ff287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9337e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4745, 0.5255, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import normalize\n",
    "t = torch.tensor([torch.rand(1),1,0,0])\n",
    "\n",
    "t1 = normalize(t, p=1.0, dim = 0)\n",
    "t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2995fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_0[:,:,5:] = np.zeros((predict_0.shape[0],predict_0.shape[1],2))\n",
    "predict_0[:,:,4:5] = np.ones((predict_0.shape[0],predict_0.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "527518d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2516709,  1.       ,  0.       ,  0.       ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_0[10,0,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb214335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0065'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '/data/jhahn/data/shape_dataset/data/brain_lightsheet/0408/fractured_0/0065.obj'\n",
    "x.split(\"/\")[-1].split(\".\")[-2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
